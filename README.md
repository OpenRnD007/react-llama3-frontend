
# Flask llama3 React Frontend

This platform offers a sophisticated chat interface that allows you to query and analyze your private documents with utmost discretion.
We are using Meta llama3 for offline LLM and Flask for exposing API  and React for frontend


## Features

- Start a Topic
  - Add Your Docs: Put in docs that are all about the topic you're talking about.
- Have a Chat
  - Ask Anything: You can ask any questions that have to do with the topic.
  - Get Insights: Feel free to ask for a deeper look or some thoughts on the topic.



## Getting Started

### Prerequisites

•  Nodejs

•  npm


### Installation

Clone the repository to your local machine:

```bash
git clone https://github.com/OpenRnD007/react-llama3-frontend.git
cd react-llama3-frontend
```

Install the required packages:
```bash
npm install
```

## Environment Variables

To run this project, you will need to add the following environment variables to your .env file

`VITE_API_URL`=`SERVER_URL`

### Running the Application
Start the server:

```bash
npm run dev
```

The server will start on http://localhost:5000/.

For gitpod

[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/OpenRnD007/react-llama3-frontend)

## DEMO
[![flask llama3 api backend](http://img.youtube.com/vi/NbXgNtWACVQ/0.jpg)](http://www.youtube.com/watch?v=NbXgNtWACVQ "flask llama3 api backend")


## License

This project is licensed under the MIT License.


## Authors

- [@openrnd007](https://www.github.com/openrnd007)
